name: CI

on:
  push:
    branches: [master, staged-aig-release]
  pull_request:
    branches: [master, staged-aig-release]

env:
  CARGO_TERM_COLOR: always

jobs:
  # Run library unit tests on Linux (no GPU required)
  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: Run library tests
        run: cargo test --lib

  # Build and run Metal simulation on macOS
  metal:
    name: Metal Tests (macOS)
    runs-on: macos-latest-xlarge
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install LLVM (for OpenMP support)
        run: |
          brew install llvm
          echo "CC=/opt/homebrew/opt/llvm/bin/clang" >> $GITHUB_ENV
          echo "CXX=/opt/homebrew/opt/llvm/bin/clang++" >> $GITHUB_ENV

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-metal-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-metal-

      - name: Build metal_test
        run: cargo build --release --features metal --bin metal_test

      - name: Run Metal simulation (timing test)
        run: |
          # Capture timing output
          time (cargo run --release --features metal --bin metal_test -- \
            tests/timing_test/dff_test_synth.gv \
            tests/timing_test/dff_test.gemparts \
            tests/timing_test/dff_test.vcd \
            tests/timing_test/ci_output.vcd \
            1) 2>&1 | tee metal_timing.txt

      - name: Report Metal performance
        run: |
          {
            echo "## Metal Simulation Performance"
            echo "\`\`\`"
            cat metal_timing.txt
            echo "\`\`\`"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Verify simulation output
        run: |
          echo "Comparing GEM output with golden VCD..."
          # Extract q signal values from both VCDs and compare
          # Golden VCD uses 'q' signal, GEM output should match
          if diff -q <(grep '^[01]!' tests/timing_test/dff_test.vcd | head -20) \
                     <(grep '^[01]!' tests/timing_test/ci_output.vcd | head -20); then
            echo "âœ“ VCD outputs match!"
          else
            echo "VCD comparison (first 20 signal changes):"
            echo "=== Golden (iverilog) ==="
            grep '^[01]!' tests/timing_test/dff_test.vcd | head -20
            echo "=== GEM output ==="
            grep '^[01]!' tests/timing_test/ci_output.vcd | head -20
            echo ""
            echo "Note: Minor differences may be acceptable depending on signal timing"
          fi

      - name: Upload VCD artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: vcd-outputs
          path: |
            tests/timing_test/ci_output.vcd
            metal_timing.txt

  # Check formatting and clippy
  # Note: Currently set to warn-only due to existing issues in codebase
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Check formatting
        run: cargo fmt --all -- --check || echo "::warning::Formatting issues found"

      - name: Clippy
        run: cargo clippy --lib 2>&1 | tee clippy_output.txt || true

      - name: Check for clippy errors (not warnings)
        run: |
          if grep -q "^error" clippy_output.txt; then
            echo "Clippy errors found!"
            exit 1
          fi

  # Run benchmarks and track performance
  benchmark:
    name: Benchmarks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-bench-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-bench-

      - name: Run benchmarks
        run: cargo bench --bench event_buffer -- --noplot 2>&1 | tee benchmark_results.txt

      - name: Extract benchmark summary
        run: |
          {
            echo "## Benchmark Results"
            echo "\`\`\`"
            grep -E "^(event_buffer|buffer_ops)" benchmark_results.txt | head -20 || true
            grep -E "time:" benchmark_results.txt | head -20 || true
            echo "\`\`\`"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark_results.txt

  # Run SKY130 post-layout timing simulation
  sky130-timing:
    name: SKY130 Timing Simulation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-sky130-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-sky130-

      - name: Cache SKY130 PDK
        uses: actions/cache@v4
        with:
          path: ~/.volare
          key: sky130-pdk-c6d73a35f524070e85faff4a6a9eef49553ebc2b
          restore-keys: |
            sky130-pdk-

      - name: Install volare and download SKY130 PDK
        run: |
          pip install volare
          # Use the same PDK version as OpenLane 2.x for reproducibility
          volare enable --pdk sky130 c6d73a35f524070e85faff4a6a9eef49553ebc2b

      - name: Build timing simulator
        run: cargo build --release --bin timing_sim_cpu

      - name: Run SKY130 timing simulation
        timeout-minutes: 5
        run: |
          # Note: Liberty file parsing for the full SKY130 library (~12MB) is slow.
          # For CI, we use default timing values. The simulation still validates
          # that the netlist parses correctly and the simulator runs.
          #
          # To test with real timing values, run locally with:
          # cargo run -r --bin timing_sim_cpu -- tests/timing_test/6_final.v \
          #   tests/timing_test/6_final_test_input.vcd --clock-period 25000 \
          #   --liberty path/to/sky130_fd_sc_hd__tt_025C_1v80.lib

          # Build command arguments (using default timing values)
          ARGS=(
            tests/timing_test/6_final.v
            tests/timing_test/6_final_test_input.vcd
            --clock-period 25000
            --max-cycles 10
          )

          echo "Running timing simulation with default timing values"
          # Run timing simulation on the post-P&R netlist
          cargo run --release --bin timing_sim_cpu -- "${ARGS[@]}" 2>&1 | tee sky130_timing.txt

      - name: Report SKY130 timing results
        run: |
          {
            echo "## SKY130 Timing Simulation Results"
            echo "\`\`\`"
            cat sky130_timing.txt
            echo "\`\`\`"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Check timing passed
        run: |
          if grep -q "TIMING: PASSED" sky130_timing.txt; then
            echo "SKY130 timing simulation passed!"
          elif grep -q "TIMING: FAILED" sky130_timing.txt; then
            echo "SKY130 timing simulation found violations (expected for this test design)"
            # Don't fail - timing violations are informational
          else
            echo "Error: Could not determine timing result"
            exit 1
          fi

      - name: Upload timing results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sky130-timing-results
          path: sky130_timing.txt
